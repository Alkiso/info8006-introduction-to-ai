class: middle, center, title-slide

# Introduction to Artificial Intelligence

Lecture 8: Making decisions

<br><br>
Prof. Gilles Louppe<br>
[g.louppe@uliege.be](g.louppe@uliege.be)

???

R: quick intro to RL
R: relation between RL and Control (see ben recht tuto at icml)
https://courses.cs.washington.edu/courses/cse473/14sp/slides/8-MDPs.pdf

R: value iteration
R: bellman equation!
R: pomdp! -> this makes the connection with lecture 7
R: finish with bandits?

R: pomdp -> lec 20 of bair

---

# Today

---

# Planning under uncertainty

agent-env loop, maintain belief state, new: make decisions

---

# Grid world

---

class: middle

# Markov decision processes

---

# Markov decision processes

---

# Policies

---

# Utility over time

- finite
- infinite horizon

- additive
- discounted -> bound the utility

---

# Optimal policies

---

# Bellman equation

---

# Value iteration

---

class: middle

## Convergence

---

# Policy iteration

---

class: middle

# Partially observable Markov decision processes

---

# POMPDs

---

# Belief MDP

---

# Value iteration

inefficient

---

# Online agents

expectiminimax solution

---

see bair 10

connection with learning and RL

bandits example?

---

# Summary

---

class: end-slide, center
count: false

The end.

---

# References
